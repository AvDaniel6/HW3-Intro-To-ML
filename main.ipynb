{"cells":[{"cell_type":"code","execution_count":2,"id":"7fcf38a3","metadata":{"executionInfo":{"elapsed":3996,"status":"ok","timestamp":1750672531159,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"},"user_tz":-180},"id":"7fcf38a3"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_validate\n","from sklearn.metrics import accuracy_score\n","from sklearn.linear_model import Lasso\n","import seaborn as sns"]},{"cell_type":"code","execution_count":3,"id":"1848b35c","metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1750672532915,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"},"user_tz":-180},"id":"1848b35c"},"outputs":[],"source":["from matplotlib import pylab\n","params = {'xtick.labelsize': 18,\n","          'ytick.labelsize': 18,\n","          'axes.titlesize': 22,\n","          'axes.labelsize': 20,\n","          'legend.fontsize': 18,\n","          'legend.title_fontsize': 22,\n","          'figure.titlesize': 24 }\n","pylab.rcParams.update(params)"]},{"cell_type":"markdown","id":"8e992e69","metadata":{"id":"8e992e69"},"source":["# Pre - processing"]},{"cell_type":"code","execution_count":4,"id":"49aac9e0","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":183,"status":"error","timestamp":1750672534810,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"},"user_tz":-180},"id":"49aac9e0","outputId":"62f01221-407c-49ee-88b0-be42d6b7e515"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'virus_data.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4-3258472411.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'virus_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mId1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mId2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m73\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mId1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mId2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'virus_data.csv'"]}],"source":["dataset = pd.read_csv('virus_data.csv')\n","\n","Id1 = 90\n","Id2 = 73\n","random_state = Id1 + Id2\n","train, test = train_test_split(dataset, test_size = 0.2, random_state = random_state)\n","\n"]},{"cell_type":"markdown","id":"e64bed32","metadata":{"id":"e64bed32"},"source":["## Pipeline From HW1"]},{"cell_type":"code","execution_count":null,"id":"47d72946","metadata":{"id":"47d72946","executionInfo":{"status":"aborted","timestamp":1750672520578,"user_tz":-180,"elapsed":4857,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}}},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","def prepare_data(training_data, new_data):\n","    my_data = new_data.copy()\n","\n","    PCR3_median = training_data['PCR_03'].median()\n","    my_data['PCR_03'] = my_data['PCR_03'].fillna(PCR3_median)\n","\n","    all_features = training_data.columns.tolist()\n","    pcr_features = [feature for feature in all_features if feature.startswith(\"PCR\")]\n","\n","    list_to_standard_scale = [feature for feature in pcr_features\n","                          if int(feature.split(\"_\")[1]) in [3, 4, 5, 6, 7, 9, 10]]\n","\n","    list_to_min_max = [feature for feature in pcr_features\n","                   if int(feature.split(\"_\")[1]) in [1, 2, 8]]\n","\n","    features_to_standard_scale = my_data[list_to_standard_scale]\n","    features_to_min_max = my_data[list_to_min_max]\n","\n","\n","    standard_scaler = StandardScaler()\n","    minmax_scaler = MinMaxScaler(feature_range=(-1, 1))\n","\n","    standard_scaler.fit(training_data[list_to_standard_scale])\n","    minmax_scaler.fit(training_data[list_to_min_max])\n","\n","\n","    standard_scaled_features = pd.DataFrame(standard_scaler.transform(features_to_standard_scale),\n","                                           columns=list_to_standard_scale,\n","                                           index=my_data.index)\n","    min_max_scaled_features = pd.DataFrame(minmax_scaler.transform(features_to_min_max),\n","                                           columns=list_to_min_max,\n","                                           index=my_data.index)\n","\n","    my_data[list_to_standard_scale] = standard_scaled_features\n","    my_data[list_to_min_max] = min_max_scaled_features\n","\n","    return my_data"]},{"cell_type":"code","execution_count":null,"id":"f5181452","metadata":{"id":"f5181452","executionInfo":{"status":"aborted","timestamp":1750672520582,"user_tz":-180,"elapsed":2,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}}},"outputs":[],"source":["train_df = prepare_data(train, train)\n","test_df = prepare_data(train, test)\n","X_train_df = train_df.drop(columns = [\"contamination_level\"])\n","y_train_df = train_df[\"contamination_level\"]\n","X_test_df = test_df.drop(columns = [\"contamination_level\"])\n","y_test_df = test_df[\"contamination_level\"]\n"]},{"cell_type":"markdown","id":"df458faa","metadata":{"id":"df458faa"},"source":["## Normalize non PCR features"]},{"cell_type":"code","execution_count":null,"id":"d872cce1","metadata":{"id":"d872cce1","executionInfo":{"status":"aborted","timestamp":1750672520589,"user_tz":-180,"elapsed":1,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}}},"outputs":[],"source":["dataset.columns"]},{"cell_type":"code","execution_count":null,"id":"0b955b23","metadata":{"id":"0b955b23","executionInfo":{"status":"aborted","timestamp":1750672520591,"user_tz":-180,"elapsed":4864,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}}},"outputs":[],"source":["X_train_df = X_train_df.drop(columns = [\"patient_id\"])\n","X_test_df = X_test_df.drop(columns = [\"patient_id\"])\n","\n","\n","# chack which normalize method to use by the feature behaviour\n","features = ['age', 'weight', 'happiness_score', 'sugar_levels']\n","for feature in features:\n","    plt.figure()\n","    sns.histplot(X_train_df[feature], kde=True)\n","    plt.title(f'Distribution of {feature}')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"d8275495","metadata":{"id":"d8275495","executionInfo":{"status":"aborted","timestamp":1750672520597,"user_tz":-180,"elapsed":4868,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}}},"outputs":[],"source":["standard_scaler = StandardScaler()\n","minmax_scaler = MinMaxScaler(feature_range=(-1, 1))\n","\n","standard_features = ['weight', 'happiness_score', 'sugar_levels']\n","minmax_features = ['age']\n","\n","standard_scaler.fit(X_train_df[standard_features])\n","X_train_df[standard_features] = standard_scaler.transform(X_train_df[standard_features])\n","X_test_df[standard_features] = standard_scaler.transform(X_test_df[standard_features])\n","\n","minmax_scaler.fit(X_train_df[minmax_features])\n","X_train_df[minmax_features] = minmax_scaler.transform(X_train_df[minmax_features])\n","X_test_df[minmax_features] = minmax_scaler.transform(X_test_df[minmax_features])\n"]},{"cell_type":"markdown","id":"1e5c5344","metadata":{"id":"1e5c5344"},"source":["# PART 1"]},{"cell_type":"markdown","id":"f3aba555","metadata":{"id":"f3aba555"},"source":["## Linear Regressor"]},{"cell_type":"code","execution_count":null,"id":"5eb0c33a","metadata":{"id":"5eb0c33a","executionInfo":{"status":"aborted","timestamp":1750672520661,"user_tz":-180,"elapsed":3,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}}},"outputs":[],"source":["X_train_part1, X_val_part1, y_train_part1, y_val_part1 = train_test_split(X_train_df, y_train_df, test_size = 0.2, random_state = random_state)"]},{"cell_type":"code","execution_count":null,"id":"daaa74e3","metadata":{"id":"daaa74e3","executionInfo":{"status":"aborted","timestamp":1750672520711,"user_tz":-180,"elapsed":52,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}}},"outputs":[],"source":["from sklearn.base import BaseEstimator, RegressorMixin\n","\n","class LinearRegressor(BaseEstimator, RegressorMixin):\n","    \"\"\"\n","    Custom linear regression model\n","    \"\"\"\n","    def __init__(self, lr: float = 1e-5):\n","        \"\"\"\n","        Initialize an instance of this class.\n","        ** Do not edit this method **\n","\n","        :param lr: the SGD learning rate (step size)\n","        \"\"\"\n","        self.lr = lr\n","        self.batch_size = 32\n","        self.w = None\n","        self.b = 0.0\n","\n","    # Initialize a random weight vector\n","    def init_solution(self, n_features: int):\n","        \"\"\"\n","        Randomize an initial solution (weight vector)\n","        ** Do not edit this method **\n","\n","        :param n_features:\n","        \"\"\"\n","        self.w = np.zeros(n_features)\n","        self.b = 0.0\n","\n","    @staticmethod\n","    def loss(w, b: float, X, y):\n","        \"\"\"\n","        Compute the MSE objective loss.\n","\n","        :param w: weight vector for linear regression; array of shape (n_features,)\n","        :param b: bias scalar for linear regression\n","        :param X: samples for loss computation; array of shape (n_samples, n_features)\n","        :param y: targets for loss computation; array of shape (n_samples,)\n","        :return: the linear regression objective loss (float scalar)\n","        \"\"\"\n","\n","        # TODO: complete the loss calculation\n","\n","        loss = np.mean((X @ w + b - y)**2)\n","\n","        return loss\n","\n","    @staticmethod\n","    def gradient(w, b: float, X, y):\n","        \"\"\"\n","        Compute the (analytical) linear regression objective gradient.\n","\n","        :param w: weight vector for linear regression; array of shape (n_features,)\n","        :param b: bias scalar for linear regression\n","        :param X: samples for loss computation; array of shape (n_samples, n_features)\n","        :param y: targets for loss computation; array of shape (n_samples,)\n","        :return: a tuple with (the gradient of the weights, the gradient of the bias)\n","        \"\"\"\n","        # TODO: calculate the analytical gradient w.r.t w and b\n","        m = len(y)\n","        g_w = 2/m * X.T @ (X @ w + b - y)\n","        g_b = 2/m * np.sum(X @ w + b - y)\n","\n","        return g_w, g_b\n","\n","    def fit_with_logs(self, X, y, max_iter: int = 1000, keep_losses: bool = True,\n","                      X_val  =None, y_val = None):\n","        \"\"\"\n","        Fit the model according to the given training data.\n","\n","        :param X: training samples; array of shape (n_samples, n_features)\n","        :param y: training targets; array of shape (n_samples,)\n","        :param max_iter: number of SGD iterations\n","        :param keep_losses: should compute the train & val losses during training?\n","        :param X_val: validation samples to compute the loss for (for logs only)\n","        :param y_val: validation labels to compute the loss for (for logs only)\n","        :return: training and validation losses during training\n","        \"\"\"\n","        # Initialize learned parameters\n","        self.init_solution(X.shape[1])\n","\n","        train_losses = []\n","        val_losses = []\n","\n","        if keep_losses:\n","            train_losses.append(self.loss(self.w, self.b, X, y))\n","            val_losses.append(self.loss(self.w, self.b, X_val, y_val))\n","\n","        # Iterate over batches (SGD)\n","        for itr in range(0, max_iter):\n","            start_idx = (itr * self.batch_size) % X.shape[0]\n","            end_idx = min(X.shape[0], start_idx + self.batch_size)\n","            batch_X = X[start_idx: end_idx]\n","            batch_y = y[start_idx: end_idx]\n","\n","            # TODO: Compute the gradient for the current *batch*\n","            g_w, g_b = self.gradient(self.w,self.b, batch_X, batch_y)\n","\n","            # Perform a gradient step\n","            # TODO: update the learned parameters correctly\n","            self.w = self.w - self.lr*g_w\n","            self.b = self.b - self.lr*g_b\n","\n","            if keep_losses:\n","                train_losses.append(self.loss(self.w, self.b,  X, y))\n","                val_losses.append(self.loss(self.w, self.b,  X_val, y_val))\n","\n","        return train_losses, val_losses\n","\n","    def fit(self, X, y, max_iter: int = 1000):\n","        \"\"\"\n","        Fit the model according to the given training data.\n","        ** Do not edit this method **\n","\n","        :param X: training samples; array of shape (n_samples, n_features)\n","        :param y: training targets; array of shape (n_samples,)\n","        :param max_iter: number of SGD iterations\n","        \"\"\"\n","        self.fit_with_logs(X, y, max_iter=max_iter, keep_losses=False)\n","\n","        return self\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Regress labels on samples in X.\n","\n","        :param X: samples for prediction; array of shape (n_samples, n_features)\n","        :return: Predicted continuous labels for samples in X; array of shape (n_samples,)\n","        \"\"\"\n","\n","        # TODO: Compute\n","        y_pred = X @ self.w + self.b\n","\n","        return y_pred"]},{"cell_type":"markdown","id":"531ffafe","metadata":{"id":"531ffafe"},"source":["## verify gradients"]},{"cell_type":"code","execution_count":null,"id":"84672bfe","metadata":{"id":"84672bfe","executionInfo":{"status":"aborted","timestamp":1750672520716,"user_tz":-180,"elapsed":57,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}}},"outputs":[],"source":["def numerical_subgradient(w, b, X, y, delta=1e-4):\n","    w_ = w.copy()\n","    g_w = np.zeros_like(w_)\n","    orig_objective = LinearRegressor.loss(w_, b, X, y)\n","    for i in range(g_w.shape[0]):\n","        w_[i] += delta\n","        perturbed_objective = LinearRegressor.loss(w_, b, X, y)\n","        w_[i] -= delta\n","        g_w[i] = (perturbed_objective - orig_objective) / delta\n","\n","    g_b = (LinearRegressor.loss(w_, b + delta, X, y) - orig_objective) / delta\n","    return g_w, g_b\n","\n","\n","def compare_gradients(X, y, deltas, C=1, REPEATS=10, figsize=(10, 6)):\n","    residual_means_w = []\n","    residual_means_b = []\n","\n","    for delta in deltas:\n","        residuals_w = []\n","        residuals_b = []\n","\n","        for _ in range(REPEATS):\n","            # Randomize vectors in which the gradient is computed\n","            w = np.random.randn(X.shape[1])\n","            b = np.random.randn(1)\n","\n","            # Compute the two types of gradients\n","            analytic_grad_w, analytic_grad_b = LinearRegressor.gradient(w, b, X, y)\n","\n","            numeric_grad_w, numeric_grad_b = numerical_subgradient(w, b, X, y, delta=delta)\n","\n","            residual_w = np.linalg.norm(numeric_grad_w - analytic_grad_w)\n","            residuals_w.append(residual_w)\n","\n","            residual_b = np.linalg.norm(numeric_grad_b - analytic_grad_b)\n","            residuals_b.append(residual_b)\n","\n","        residual_means_w.append(np.mean(residuals_w))\n","        residual_means_b.append(np.mean(residuals_b))\n","\n","    fig, axs = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(16, 8))\n","    plt.suptitle('Residuals of analytical and numerical gradients',\n","                 fontsize=22, fontweight=\"bold\")\n","    axs[0].set_title(r'Residuals of $\\nabla_{w}L\\left(w,b\\right)$')\n","    axs[1].set_title(r'Residuals of $\\frac{\\partial}{\\partial{b}}L\\left(w,b\\right)$')\n","    axs[0].plot(deltas, residual_means_w, linewidth=3)\n","    axs[1].plot(deltas, residual_means_b, linewidth=3)\n","    axs[0].set_yscale('log')\n","    axs[0].set_xscale('log')\n","    axs[1].set_yscale('log')\n","    axs[1].set_xscale('log')\n","    axs[0].set_xlabel('$\\delta_w$', fontsize=18)\n","    axs[1].set_xlabel('$\\delta_b$', fontsize=18)\n","    axs[0].set_ylabel(r'$\\left\\Vert \\nabla_{w}L\\left(w,b\\right) - u_{\\delta_w} \\left(w,b\\right)\\right\\Vert$',\n","                      fontsize=18)\n","    axs[1].set_ylabel(\n","        r'$\\left\\Vert \\frac{\\partial}{\\partial{b}}L\\left(w,b\\right) - u_{\\delta_b} \\left(w,b\\right)\\right\\Vert$',\n","        fontsize=18)\n","\n","    axs[0].grid(alpha=0.5)\n","    axs[1].grid(alpha=0.5)\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"ca00040a","metadata":{"id":"ca00040a","executionInfo":{"status":"aborted","timestamp":1750672520717,"user_tz":-180,"elapsed":57,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}}},"outputs":[],"source":["compare_gradients(X_train_part1, y_train_part1, deltas=np.logspace(-7,-2,9))"]},{"cell_type":"markdown","id":"c4c3dd01","metadata":{"id":"c4c3dd01"},"source":["## test_lr"]},{"cell_type":"code","execution_count":null,"id":"74c913b6","metadata":{"id":"74c913b6","executionInfo":{"status":"aborted","timestamp":1750672520719,"user_tz":-180,"elapsed":4983,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}}},"outputs":[],"source":["def test_lr(X_train, y_train, X_val, y_val, title:str, max_iter = 1500):\n","  lr_list = np.logspace(-9, -1, 9)\n","\n","  fig, axs = plt.subplots(3, 3, sharey=True, figsize=(20, 12))\n","  plt.suptitle(title, fontsize=32)\n","  plt.tight_layout()\n","  fig.subplots_adjust(hspace=0.5, top=0.9)\n","\n","  axs = np.ravel(axs)\n","  for i, lr in enumerate(lr_list):\n","    cur_linear_reggressor = LinearRegressor(lr)\n","    train_losses, val_losses = cur_linear_reggressor.fit_with_logs(X_train, y_train, keep_losses=True, X_val=X_val, y_val=y_val, max_iter = max_iter)\n","    print('lr size = '+str(lr)+', Best train loss = '+str(min(train_losses))+', Best validation loss = '+str(min(val_losses)))\n","\n","    iterations = np.arange(max_iter + 1)\n","    axs[i].semilogy(iterations, train_losses, label=\"Train\")\n","    axs[i].semilogy(iterations, val_losses, label=\"Validation\")\n","    axs[i].grid(alpha=0.5)\n","    axs[i].legend()\n","    axs[i].set_title('lr = '+str(lr))\n","    axs[i].set_xlabel('iteration')\n","    axs[i].set_ylabel('MSE')"]},{"cell_type":"code","execution_count":null,"id":"8bb6306e","metadata":{"id":"8bb6306e","executionInfo":{"status":"aborted","timestamp":1750672520721,"user_tz":-180,"elapsed":4982,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}}},"outputs":[],"source":["test_lr(X_train_part1, y_train_part1, X_val_part1, y_val_part1, title = \"Training and validation loss as a function of learning rate\")"]},{"cell_type":"markdown","source":["## PART 2"],"metadata":{"id":"cAoaMEVOI0lb"},"id":"cAoaMEVOI0lb"},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"r71_WFGlI6UG","executionInfo":{"status":"error","timestamp":1750672520545,"user_tz":-180,"elapsed":4609,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}},"outputId":"da9897df-1445-4b71-9352-dda9a20f64ac"},"id":"r71_WFGlI6UG","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'X_train' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1-1817146552.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m cv_results = cross_validate(\n\u001b[1;32m     10\u001b[0m     \u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"]}]},{"cell_type":"markdown","id":"1a789f93","metadata":{"id":"1a789f93"},"source":["# Part 3"]},{"cell_type":"code","execution_count":null,"id":"6a0baef6","metadata":{"id":"6a0baef6","executionInfo":{"status":"aborted","timestamp":1750672520722,"user_tz":-180,"elapsed":4980,"user":{"displayName":"eden elgavi","userId":"05873533133076745011"}}},"outputs":[],"source":["alpha_values = np.logspace(-10, 9, 20)\n","train_score = []\n","test_score = []\n","for val in alpha_values:\n","    linear_lasso = Lasso(alpha = val, fit_intercept=True)\n","    results = cross_validate(linear_lasso, X_train_df, y_train_df, cv = 5, scoring='neg_mean_squared_error', return_train_score=True)\n","    train_score.append(np.mean(results[\"train_score\"]))\n","    test_score.append(np.mean(results[\"test_score\"]))\n","\n","plt.semilogx(alpha_values, train_score, label=\"Train Accuracy\", marker = 'o')\n","plt.semilogx(alpha_values, test_score, label=\"Validation Accuracy\", marker = 'o')\n","plt.xlabel(\"alpha hyperparameter\")\n","plt.ylabel(\"Negative MSE\")\n","plt.title(\"Validation Curve: Lasso linear regressor on all features\")\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.3"}},"nbformat":4,"nbformat_minor":5}